{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Toxic_distillation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sverdoot/VK_test_task/blob/master/toxic_distillation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pZ2qe9PHAaCz",
        "colab_type": "text"
      },
      "source": [
        "# Тестовое задание в лабораторию ВК, команда прикладных исследований. \n",
        "Выполнил Женя Лагутин"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75GI73DtAsQw",
        "colab_type": "text"
      },
      "source": [
        "Построение легковестных моделей - одна из хайповых тем. Действительно, количество параметров SOTA моделей растёт с ужасающим темпом. Не очень ясно, как использовать в production такие language models, как BERT или, тем более, RoBERTa, которые при этом дают очень хорошее качество. \n",
        "\n",
        "В последнее время сжатию тяжеловесвтных моделей посвящают всё больше исследований: Distilling BERT into BiLSTM, DistilBERT от HuggingFace, BERT Quantization от Intel и, совсем недавно, Tiny BERT от Huawei.\n",
        "\n",
        "Основная идея этих работ - взять хорошо обученную, но тяжёлую бертоподобную языковую модель и сжать ее, например, в бертоподобную модель меньшего размера. Среди способов это сделать:\n",
        "* Сделать tensor-train разложение тензора эмбеддингов или feedforward слоёв трансформера\n",
        "* Квантизовать эмбеддинги или feedforward слои трансформера\n",
        "* Прунить BERT, уменьшая число слоёв attention, и число голов multi-head attention'ов\n",
        "\n",
        "И наконец:\n",
        "* Knowledge distillation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v7BiGo1OEW3h",
        "colab_type": "text"
      },
      "source": [
        "Я решил попробовать последний метод, так как он позволяет сжать BERT до произвольного размера, а так же не требует дополнительных манипуляций для ускорения модели, как, например, при квантизации. Моя teacher model - fine-tuned BERT-Base. В качестве student модели для дистилляции я выбрал обычную логистическую регрессию, принимающу на вход TF-IDF признаки. Такая модель будет, пожалуй, максимально лёгкой и быстрой."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6n8md4TDD0l",
        "colab_type": "text"
      },
      "source": [
        "Однако, обучить BERT на колабе оказалось не такой простой задачей, как я предполагал... Колаб вёл себя капризно как никогда. В результате особо хорошего качества от BERT'a получить не удалось и пришлось работать с тем, что есть. Результаты представлены ниже."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pugh67w_HuPU",
        "colab_type": "text"
      },
      "source": [
        "## Какие есть способы ускорения/уменьшения модели\n",
        "\n",
        "**Ускорение:** \"умная\" квантизация (позволяющая превратить некоторые матричные операции в векторные; не любая реализация квантизации будет ускорять модель), прунинг (как уменьшение количества слоёв и голов)\n",
        "\n",
        "**Уменьшение:** квантизация, матричные разложения (tensor-train, SVD в матричном случае), прунинг (в том числе уменьшение количества ненулевых весов), дистилляция\n",
        "\n",
        "Если выбирать методом исключения, то останется дистилляция. \n",
        "\n",
        "Для квантизации нужно дополнительноучитряться, чтобы получить ускорение. \n",
        "\n",
        "Матричные разложения не дадут мне значительно уменьшить модель. Можно, конечно, использовать маленькую модель поверх разложенных эмбеддингов BERT'а, но всё-таки такой подход приводит к увеличению матричных умножений и, как следствие, замедлению инференса.\n",
        "\n",
        "Прунинг помог бы мне уменьших модель в несколько раз, может в 10, но не в сотни раз.\n",
        "\n",
        "Дистилляция же оставляет простор для выбора достаточно маленькой и достаточно быстрой модели."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl0RR3JiJa32",
        "colab_type": "text"
      },
      "source": [
        "## Что лучше - сразу маленькая модель или большая и потом её оптимизировать?\n",
        "\n",
        "Существует ряд примеров, когда второй подход даёт лучший результат. В случае с дистилляцией это связано с тем, что логиты, на которых обучается student модель, содержат дополнительную информацию, которую маленькая модель попросту не может выучить сама по себе (lack of capacity). То есть то, что вероятности отсутствующих классов не нули, позволяет маленькой модели извлечь скрытые зависимости из данных."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anJAN9dFKq1_",
        "colab_type": "text"
      },
      "source": [
        "## Недостатки моего модхода\n",
        "\n",
        "Недостатки моего подхода становятся более явными в том случае, когда teacher модель обучена недостаточно хорошо, как в моём случае. Получается, что student модель обучается на недоостаточно правдивых данных. Я попытался это исправить, не позволяя модели учится на \"ложных\" логитах, подсовывая ей вместо этого реальный таргет.\n",
        "\n",
        "Другой недостаток дистилляции как подхода: насколько я понимаю, пока нет гарантий, что дистилляция улучшает качество в общем случае."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWDDjULJQSlM",
        "colab_type": "text"
      },
      "source": [
        "## Код:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aXzdh7cBQgBw",
        "colab_type": "text"
      },
      "source": [
        "Далее, в качестве хранилища я использую папку 'toxic_distill' на гугл диске. Чтобы всё работало - создайте такую и у себя)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gi8ou6xQ--ZN",
        "colab_type": "code",
        "outputId": "c8399473-88dd-4fb5-d3d9-03648bbd0bf4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKErf7GBQWwu",
        "colab_type": "text"
      },
      "source": [
        "Код для загруки данных с kaggle, используя kaggle api"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4UDJNL8XXKdv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#from google.colab import files\n",
        "#files.upload()\n",
        "\n",
        "#!mkdir -p ~/.kaggle\n",
        "#!cp \"kaggle.json\" ~/.kaggle/\n",
        "\n",
        "#!pip install -q kaggle\n",
        "##!chmod 600 /root/.kaggle/kaggle.json\n",
        "#!kaggle competitions download -c jigsaw-toxic-comment-classification-challenge\n",
        "\n",
        "#import zipfile\n",
        "#with zipfile.ZipFile('train.csv.zip', 'r') as zip_ref:\n",
        "#    zip_ref.extractall('drive/My Drive/toxic_distill')\n",
        "#with zipfile.ZipFile('test.csv.zip', 'r') as zip_ref:\n",
        "#    zip_ref.extractall('drive/My Drive/toxic_distill')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nvR_K5UYiWU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S5EO3zu6Y-Ko",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('drive/My Drive/toxic_distill/train.csv')\n",
        "#test_df = pd.read_csv('test.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FLhgHoVlZLiW",
        "colab_type": "code",
        "outputId": "3379988f-9b40-44dc-8e61-433023817f93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        }
      },
      "source": [
        "df[:5]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>comment_text</th>\n",
              "      <th>toxic</th>\n",
              "      <th>severe_toxic</th>\n",
              "      <th>obscene</th>\n",
              "      <th>threat</th>\n",
              "      <th>insult</th>\n",
              "      <th>identity_hate</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0000997932d777bf</td>\n",
              "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000103f0d9cfb60f</td>\n",
              "      <td>D'aww! He matches this background colour I'm s...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>000113f07ec002fd</td>\n",
              "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0001b41b1c6bb37e</td>\n",
              "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0001d958c54c6e35</td>\n",
              "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                 id  ... identity_hate\n",
              "0  0000997932d777bf  ...             0\n",
              "1  000103f0d9cfb60f  ...             0\n",
              "2  000113f07ec002fd  ...             0\n",
              "3  0001b41b1c6bb37e  ...             0\n",
              "4  0001d958c54c6e35  ...             0\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UMwvqHXoEejb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "label_names = list(df.columns[-6:])\n",
        "n_labels = 6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7zcTncqFRFSl",
        "colab_type": "text"
      },
      "source": [
        "Я разделил данные на train и dev в соотношении 4:1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5uzuTlhGnvZ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_df = df[:int(len(df)*0.8)]\n",
        "dev_df = df[-int(len(df)*0.2):]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ss9KrHv1RNtj",
        "colab_type": "text"
      },
      "source": [
        "Как видно из следующей клетки, объектов каждого класса довольно мало по отношению к общему колиству комментариев, так что, построить уверенный классификатор довольно непросто."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yuUT3Ox4Z82O",
        "colab_type": "code",
        "outputId": "4b04d547-3630-4f0e-e887-d6cfeddee928",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "print('Train:\\t', [f'{x[0]}: {x[1]*100.:.2f}%' for x in zip(label_names, np.array(train_df.iloc[:, 3:]).sum(0) / len(train_df))])\n",
        "print('Dev:\\t', [f'{x[0]}: {x[1]*100.:.2f}%' for x in zip(label_names, np.array(dev_df.iloc[:, 3:]).sum(0) / len(dev_df))])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train:\t ['toxic: 1.01%', 'severe_toxic: 5.31%', 'obscene: 0.30%', 'threat: 4.93%', 'insult: 0.86%']\n",
            "Dev:\t ['toxic: 0.97%', 'severe_toxic: 5.23%', 'obscene: 0.29%', 'threat: 4.96%', 'insult: 0.96%']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-I6xZOndRtTs",
        "colab_type": "text"
      },
      "source": [
        "Pretrained bert я позаимствую из репозитория hugging face - pytorch-transformers."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qtiheSYeZM9o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pytorch-transformers==1.2.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiyvQcSYZihN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from pytorch_transformers import *\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "import numpy as np\n",
        "import time\n",
        "from torch import optim\n",
        "from torch.optim.lr_scheduler import LambdaLR"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uzixrxg5tYKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sigmoid = lambda x : 1 / (1 + np.exp(-x)) # sigmoid for numpy arrays\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  device = 0\n",
        "else:\n",
        "  device = 'cpu'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1zRUz4kxVRfc",
        "colab_type": "text"
      },
      "source": [
        "## Teacher:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CP9vFlBX0SwR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "teacher_n_epoch = 4\n",
        "teacher_lr = 3e-5\n",
        "teacher_warmup_proportion = 0.1\n",
        "teacher_batch_size = 32\n",
        "teacher_max_seq_len = 150\n",
        "teacher_dropout = 0.25\n",
        "max_seq_len = 128\n",
        "\n",
        "teacher_path = None # teacher model storage\n",
        "logits_path = None # teacher's logits storage"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OKs8EpB9aDAI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2e5fb0d0-860e-469f-e1b4-80e8e15fe4f2"
      },
      "source": [
        "bert_tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 231508/231508 [00:00<00:00, 939624.88B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CT6X1uDBcPE_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PAD_TOKEN = bert_tokenizer.pad_token\n",
        "PAD_TOKEN_ID = bert_tokenizer.pad_token_id\n",
        "CLS_TOKEN = bert_tokenizer.cls_token\n",
        "\n",
        "bert_config = BertConfig()\n",
        "bert_hidden_size = bert_config.hidden_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W6NPFQyR_j0",
        "colab_type": "text"
      },
      "source": [
        "Здесь всё просто - я не стал замарачиваться и просто добавил линейный слой поверх выхода берта cls токена. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4Can9ZIbmEi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertTeacher(BertModel):\n",
        "    def __init__(self, bert_config, num_labels=6, pad_id=0, dropout=0.):\n",
        "        super(BertTeacher, self).__init__(bert_config)\n",
        "        self.num_labels = num_labels\n",
        "        self.bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.linear = torch.nn.Linear(bert_config.hidden_size, num_labels)\n",
        "        self.pad_id = pad_id\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        _, pooled_output = self.bert(input_ids, (input_ids!=0).long())\n",
        "        pooled_output = self.dropout(pooled_output)\n",
        "        logits = self.linear(pooled_output)\n",
        "        return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4h79arygi3AU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TeacherDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, transform=None):\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "            \n",
        "        comment_text = self.dataframe.iloc[idx, 1]\n",
        "        labels = torch.LongTensor((self.dataframe.iloc[idx, 2:]))\n",
        "        \n",
        "        if self.transform:\n",
        "          comment_text = torch.LongTensor(self.transform(comment_text))\n",
        "\n",
        "        sample = {'comment_text': comment_text, 'labels': labels}\n",
        "\n",
        "        return sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MuzSk94KSSKn",
        "colab_type": "text"
      },
      "source": [
        "Следующая функция позволяет собрать статистику длин комментариев в токенах. Как оказалось, чтобы покрыть 85% комментариев целиком, длина должна быть порядка 150 токенов (!) - очередной вызов для колаба."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kWXPt4-Emx_R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq_len_stat(texts, tokenizer, quantile=0.85):\n",
        "  lens = []\n",
        "  for comment in train_df['comment_text']:\n",
        "    lens.append(len(bert_tokenizer.tokenize(comment)))\n",
        "  print(f'Mean length: {np.mean(lens)}, median: {np.median(lens)}, length covering {quantile:.2f} sequences: {np.quantile(lens, quantile)}')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjNjvMtglv-z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextProcessing():\n",
        "  \n",
        "  def __init__(self, tokenizer, max_len=100):\n",
        "    self.tokenizer = tokenizer\n",
        "    self.pad_token = tokenizer.pad_token\n",
        "    self.cls_token = tokenizer.cls_token\n",
        "    self.max_len = max_len\n",
        "    \n",
        "  def __call__(self, text):\n",
        "    tokens = self.tokenizer.tokenize(text)\n",
        "    tokens = tokens[:self.max_len]\n",
        "    tokens += [self.pad_token]*(self.max_len - len(tokens))\n",
        "    tokens = [self.cls_token] + tokens\n",
        "    return torch.tensor(self.tokenizer.convert_tokens_to_ids(tokens)).long()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxbxTEeOqFaR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "teacher_transform = TextProcessing(bert_tokenizer, max_len=max_seq_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1OawYIBkKyu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = TeacherDataset(train_df, teacher_transform)\n",
        "dev_dataset = TeacherDataset(dev_df, teacher_transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kShR6J8iJ1PW",
        "colab": {}
      },
      "source": [
        "train_batcher = DataLoader(train_dataset, batch_size=teacher_batch_size, shuffle=False)\n",
        "dev_batcher = DataLoader(dev_dataset, batch_size=teacher_batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-O5IMz6gYU1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# function for printing classification report and roc_auc_score\n",
        "\n",
        "def report(y_true, probs, label_names):\n",
        "  y_pred = (probs >= 0.5)\n",
        "  avg_roc_auc = 0\n",
        "  for i, label_name in enumerate(label_names):\n",
        "    print(f'CLASS: {label_name.upper()}')\n",
        "    print(classification_report(y_true[:,i], y_pred[:,i]))\n",
        "    roc_auc = roc_auc_score(y_true[:,i], probs[:,i])\n",
        "    print(f'ROC-AUC score: {roc_auc}')\n",
        "    avg_roc_auc += roc_auc\n",
        "  avg_roc_auc /= len(label_names)\n",
        "  print(avg_roc_auc)\n",
        "  \n",
        "  return avg_roc_auc"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0yI-uCfrZZT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "criterion = nn.BCEWithLogitsLoss() # for multilabel classification"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "caamuADosHDk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "998c319f-ecb7-4aa7-c592-ece8fe6245e5"
      },
      "source": [
        "teacher_model = BertTeacher(bert_config, n_labels, PAD_TOKEN_ID, teacher_dropout).to(device)\n",
        "\n",
        "teacher_optimizer = AdamW(teacher_model.parameters(), lr=teacher_lr)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 313/313 [00:00<00:00, 118027.25B/s]\n",
            "100%|██████████| 440473133/440473133 [00:16<00:00, 26996330.95B/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2GJf38M0Tqj0",
        "colab_type": "text"
      },
      "source": [
        "Следуя заветам fine-tuning'a BERT'a, я добавил warmup, однако пришлось от него отказаться, так как процесс обучения на колабе не позволяет планировать наперёд)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4RmS1Wv1z4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# code from hugging_face/transformers\n",
        "\n",
        "class WarmupLinearSchedule(LambdaLR):\n",
        "    \"\"\" Linear warmup and then linear decay.\n",
        "        Linearly increases learning rate from 0 to 1 over `warmup_steps` training steps.\n",
        "        Linearly decreases learning rate from 1. to 0. over remaining `t_total - warmup_steps` steps.\n",
        "    \"\"\"\n",
        "    def __init__(self, optimizer, warmup_steps, t_total, last_epoch=-1):\n",
        "        self.warmup_steps = warmup_steps\n",
        "        self.t_total = t_total\n",
        "        super(WarmupLinearSchedule, self).__init__(optimizer, self.lr_lambda, last_epoch=last_epoch)\n",
        "\n",
        "    def lr_lambda(self, step):\n",
        "        if step < self.warmup_steps:\n",
        "            return float(step) / float(max(1, self.warmup_steps))\n",
        "        return max(0.0, float(self.t_total - step) / float(max(1.0, self.t_total - self.warmup_steps)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCAU8dzy2scH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "total_n_steps = len(train_df) / teacher_batch_size * teacher_n_epoch\n",
        "warmup_steps = int(total_n_steps * teacher_warmup_proportion)\n",
        "teacher_scheduler = WarmupLinearSchedule(teacher_optimizer, warmup_steps, total_n_steps)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_TBRIkNS8Js",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#teacher_path = 'drive/My Drive/toxic_distill/teacher.pt'\n",
        "\n",
        "if teacher_path is not None:\n",
        "  chkpnt = torch.load(teacher_path)\n",
        "  teacher_model.load_state_dict(chkpnt['model_state_dict'])\n",
        "  teacher_optimizer.load_state_dict(chkpnt['optimizer'])\n",
        "  lock_loss = chkpnt['loss']\n",
        "else:\n",
        "  lock_loss = float('Inf')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7cThK1Roih1",
        "colab_type": "text"
      },
      "source": [
        "*Комментарий: в процеесе обучения я вывожу следующие метрики: процент объектов, для которых предсказание целиком верное (full_match_acc), и общие процент верно предсказанных меток (part-match-acc)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Qp5Exm5sXSf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training loop\n",
        "\n",
        "print_every = 300 \n",
        "\n",
        "for epoch in range(teacher_n_epoch):\n",
        "    teacher_model.train()\n",
        "    train_loss = 0\n",
        "    train_logits =[]\n",
        "    train_part_match = 0\n",
        "    train_exact_match = 0\n",
        "    n_ex = 0  # number of processed examples\n",
        "    epoch_time = time.time()\n",
        "    \n",
        "    for batch_id, batch in enumerate(train_batcher):\n",
        "      teacher_optimizer.zero_grad()\n",
        "      comment = batch['comment_text'].to(device)\n",
        "      target = batch['labels'].to(device)\n",
        "      n_ex += comment.size(0)\n",
        "\n",
        "      out = teacher_model(comment)\n",
        "      train_logits.append(out.detach().cpu().numpy())\n",
        "      pred = (out.sigmoid() >= 0.5).long()\n",
        "      \n",
        "      loss = criterion(out.view(-1, n_labels), target.float().view(-1, n_labels))\n",
        "      train_loss += loss.item()\n",
        "      loss.backward()\n",
        "      teacher_optimizer.step()\n",
        "      #teacher_scheduler.step()\n",
        "      \n",
        "      train_exact_match += torch.sum(torch.sum(pred == target, 1) == n_labels).item()\n",
        "      train_part_match += torch.sum(pred == target).item()\n",
        "\n",
        "      if batch_id % print_every == 0 and batch_id > 0:\n",
        "        print(f'\\tIteration {batch_id}. Training loss: {(train_loss / batch_id):.7f}, full-match acc: {(train_exact_match / n_ex):.3f}, ' + \\\n",
        "        f'part-match acc {(train_part_match / n_ex / n_labels):.3f}')\n",
        "    \n",
        "    print(f'Epoch {epoch}. Training loss: {(train_loss / batch_id):.7f}, full-match acc: {(train_exact_match / n_ex):.3f}, ' + \\\n",
        "        f'part-match acc {(train_part_match / n_ex / n_labels):.3f}')\n",
        "    train_logits = np.vstack(train_logits)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      teacher_model.eval()\n",
        "      val_loss = 0\n",
        "      n_ex = 0\n",
        "      val_exact_match = 0\n",
        "      val_part_match = 0\n",
        "      y_pred = []\n",
        "      y_true = []\n",
        "      dev_logits = []\n",
        "      \n",
        "      for batch_id, batch in enumerate(dev_batcher):\n",
        "        comment = batch['comment_text'].to(device)\n",
        "        target = batch['labels'].to(device)\n",
        "        n_ex += comment.size(0)\n",
        "        \n",
        "        out = teacher_model(comment)\n",
        "        dev_logits.append(out.detach().cpu().numpy())\n",
        "        pred = (out.sigmoid() >= 0.5).long()\n",
        "        \n",
        "        loss = criterion(out.view(-1, n_labels), target.float().view(-1, n_labels))\n",
        "        val_loss += loss.item()\n",
        "        \n",
        "        val_exact_match += torch.sum(torch.sum(pred == target, 1) == n_labels).item()\n",
        "        val_part_match += torch.sum(pred == target).item()\n",
        "        \n",
        "        y_pred += pred.tolist()\n",
        "        y_true += target.tolist()\n",
        "\n",
        "        if batch_id % print_every == 0 and batch_id > 0:\n",
        "          print(f'\\tIteration {batch_id}. Validation loss: {(val_loss / batch_id):.7f}')\n",
        "      \n",
        "      print(f'Epoch {epoch}. Validation loss: {(val_loss / batch_id):.7f}, full-match acc: {(val_exact_match / n_ex):.3f}, ' + \\\n",
        "        f'part-match acc {(val_part_match / n_ex / n_labels):.3f}')\n",
        "      dev_logits = np.vstack(dev_logits)\n",
        "      \n",
        "      y_pred = np.array(y_pred)\n",
        "      y_true = np.array(y_true)\n",
        "      avg_roc_auc = report(y_true, sigmoid(dev_logits), label_names)\n",
        "   \n",
        "      if val_loss < lock_loss:\n",
        "        lock_loss = val_loss\n",
        "        lock_avg_roc_auc = avg_roc_auc\n",
        "        torch.save({'model_state_dict': teacher_model.state_dict(),\n",
        "                     'optimizer': teacher_optimizer.state_dict(),\n",
        "                     'loss': val_loss / batch_id,\n",
        "                     'full-match acc': val_exact_match / n_ex,\n",
        "                     'avg_roc_auc': avg_roc_auc,\n",
        "                     'part-match acc': val_part_match / n_ex / n_labels,\n",
        "                     'pred_true': (y_pred, y_true),\n",
        "                     'epoch': epoch}, 'drive/My Drive/toxic_distill/teacher.pt')\n",
        "        torch.save({'train_logits':train_logits, 'dev_logits':dev_logits}, 'drive/My Drive/toxic_distill/logits.pt')\n",
        "     "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eo2qG1543tBM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "logits = 'drive/My Drive/toxic_distill/logits.pt'\n",
        "logits = torch.load(logits)\n",
        "dev_logits = logits['dev_logits']\n",
        "train_logits = logits['train_logits']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qZ4O4d6aUy_c",
        "colab_type": "text"
      },
      "source": [
        "Далее - результаты fine-tuning'a BERT Base, качество на валидационном сете. Not great, not terrible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrcXBPaUEzVU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# shows the report\n",
        "report(np.array(dev_df.iloc[:, 2:]), sigmoid(dev_logits), label_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsefsCe9OhwQ",
        "colab_type": "text"
      },
      "source": [
        "### Report:\n",
        "\n",
        "CLASS: TOXIC\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.98      0.98      0.98     28877\n",
        "           1       0.80      0.82      0.81      3037\n",
        "\n",
        "ROC-AUC score: 0.9800327023719385\n",
        "\n",
        "CLASS: SEVERE_TOXIC\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.99      1.00      1.00     31603\n",
        "           1       0.65      0.15      0.25       311\n",
        "\n",
        "ROC-AUC score: 0.9890117884327193\n",
        "\n",
        "CLASS: OBSCENE\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.99      0.99      0.99     30245\n",
        "           1       0.84      0.81      0.83      1669\n",
        "\n",
        "ROC-AUC score: 0.9889399046988044\n",
        "\n",
        "CLASS: THREAT\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       1.00      1.00      1.00     31822\n",
        "           1       0.56      0.32      0.40        92\n",
        "\n",
        "ROC-AUC score: 0.9725331873218693\n",
        "\n",
        "CLASS: INSULT\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.99      0.99      0.99     30332\n",
        "           1       0.77      0.73      0.75      1582\n",
        "\n",
        "ROC-AUC score: 0.9855226683947542\n",
        "\n",
        "CLASS: IDENTITY_HATE\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.99      1.00      1.00     31609\n",
        "           1       0.75      0.34      0.47       305\n",
        "\n",
        "ROC-AUC score: 0.9858376608861659\n",
        "\n",
        "**AVG ROC-AUC: 0.9836463186843751**\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GOX5Qajhq63Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# supplementary stuff\n",
        "\n",
        "def collect_logits(model, batcher, device):\n",
        "  with torch.no_grad():\n",
        "    model.eval()\n",
        "    logits = []\n",
        "    \n",
        "    for batch_id, batch in enumerate(batcher):\n",
        "      comment = batch['comment_text'].to(device)\n",
        "      target = batch['labels'].to(device)\n",
        "      \n",
        "      out = model(comment)\n",
        "      logits.append(out.detach().cpu().numpy())\n",
        "  logits = np.vstack(logits)\n",
        "  \n",
        "  return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ECf4LZPVJbA",
        "colab_type": "text"
      },
      "source": [
        "## Student:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zfV5VtkM4QFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "student_batch_size = 64\n",
        "student_lr = 0.1\n",
        "student_momentum = 0.9\n",
        "n_word_features = 10000\n",
        "n_char_features = 10000\n",
        "student_n_epoch = 6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krhDBrTHzRrZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class MultilabelLinearRegression(nn.Module):\n",
        "  \n",
        "  def __init__(self, input_dim, n_classes):\n",
        "    super(MultilabelLinearRegression, self).__init__()\n",
        "    \n",
        "    self.input_dim = input_dim\n",
        "    self.n_classes = n_classes\n",
        "    self.lin = nn.Linear(input_dim, n_classes)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "    \n",
        "  def forward(self, inp):\n",
        "    output = self.lin(inp.float())\n",
        "    return output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fsbrULaEVvY2",
        "colab_type": "text"
      },
      "source": [
        "Как было сказано выше, в качестве признаков для логистической регрессии я выбрал tf-idf. Код для сбора tf-idf я загуглил."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdOiwgsZzcvq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.pipeline import Pipeline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HVx71qxn-uFL",
        "colab_type": "code",
        "outputId": "7c295b01-5f30-4600-ef36-8a8919d3592c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "word_vectorizer = TfidfVectorizer(\n",
        "    sublinear_tf=True,\n",
        "    strip_accents='unicode',\n",
        "    analyzer='word',\n",
        "    token_pattern=r'\\w{1,}',\n",
        "    stop_words='english',\n",
        "    ngram_range=(1, 1),\n",
        "    max_features=n_word_features)\n",
        "word_vectorizer.fit(train_df['comment_text'])\n",
        "\n",
        "char_vectorizer = TfidfVectorizer(\n",
        "    sublinear_tf=True,\n",
        "    strip_accents='unicode',\n",
        "    analyzer='char',\n",
        "    stop_words='english',\n",
        "    ngram_range=(2, 6),\n",
        "    max_features=n_char_features)\n",
        "char_vectorizer.fit(train_df['comment_text'])"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TfidfVectorizer(analyzer='char', binary=False, decode_error='strict',\n",
              "                dtype=<class 'numpy.float64'>, encoding='utf-8',\n",
              "                input='content', lowercase=True, max_df=1.0, max_features=10000,\n",
              "                min_df=1, ngram_range=(2, 6), norm='l2', preprocessor=None,\n",
              "                smooth_idf=True, stop_words='english', strip_accents='unicode',\n",
              "                sublinear_tf=True, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                tokenizer=None, use_idf=True, vocabulary=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PdSxxAi7PR4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class StudentDataset(Dataset):\n",
        "\n",
        "    def __init__(self, dataframe, logits, transform=None):\n",
        "        assert len(dataframe) == len(logits)\n",
        "        self.dataframe = dataframe\n",
        "        self.transform = transform\n",
        "        self.logits = logits\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataframe)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        if torch.is_tensor(idx):\n",
        "            idx = idx.tolist()\n",
        "            \n",
        "        logits = torch.FloatTensor(self.logits[idx])\n",
        "        comment_text = self.dataframe.iloc[idx, 1]\n",
        "        labels = torch.LongTensor((self.dataframe.iloc[idx, 2:]))\n",
        "        \n",
        "        if self.transform:\n",
        "          comment_text = self.transform(comment_text)\n",
        "\n",
        "        sample = {'comment_text': comment_text, 'labels': labels, 'logits': logits}\n",
        "\n",
        "        return sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fURu4loO-8RG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.sparse import hstack\n",
        "\n",
        "def lr_transform(text):  \n",
        "  return torch.tensor(hstack([word_vectorizer.transform([text]), char_vectorizer.transform([text])]).todense()).float()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zH-u2RyGKmP1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_train_dataset = StudentDataset(train_df, train_logits, lr_transform)\n",
        "lr_dev_dataset = StudentDataset(dev_df, dev_logits, lr_transform)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUn4Kq1SO7Qd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr_train_batcher = DataLoader(lr_train_dataset, batch_size=student_batch_size, shuffle=False)\n",
        "lr_dev_batcher = DataLoader(lr_dev_dataset, batch_size=student_batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oMfi5WFGUNhs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "student_model = MultilabelLinearRegression(n_char_features+n_word_features, n_labels).to(device)\n",
        "\n",
        "student_optimizer = optim.SGD(student_model.parameters(), lr=student_lr, nesterov=True, momentum=student_momentum)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaoi8T5jWCiO",
        "colab_type": "text"
      },
      "source": [
        "Здесь развилка: как обучать логистическую регрессию на логитах? \n",
        "\n",
        "* Первый способ - минимизация $l_p$ расстояния между логитами учителя и студента. \n",
        "* Второй же - более изощрённый - минимизация KL-дивергенции между вероятностями одной модели и другой. В этом случае, моя цель, сделать, чтобы апостериорное распределение студента описывало апостериорное распределение учителя. Кроме того, как было сказано выше, в случаях, когда учитель ошибался, я подсовывал студенту правильный овет в качестве таргета, что соответствует минимизации классической бинарной кросс энтропии.\n",
        "\n",
        "Проведя эксперимент, я пришёл к выводу, что первый способ ($p=2$, т.е. обычный метод наименьших квадратов) даёт лучший результат. Возможно потому, что непосредственно логиты оказались более полезными для обучения линейной модели, чем нормированные вероятности.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lMNxka5bU53f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "distill_criterion = nn.MSELoss() #nn.KLDivLoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewQxHNs3cGYx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn25IB1eVdus",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# training loop\n",
        "\n",
        "lock_loss = 0\n",
        "print_every = 100\n",
        "\n",
        "for epoch in range(student_n_epoch):\n",
        "    student_model.train()\n",
        "    train_loss = 0\n",
        "    train_part_match = 0\n",
        "    train_exact_match = 0\n",
        "    n_ex = 0  # number of processed examples\n",
        "    \n",
        "    for batch_id, batch in enumerate(lr_train_batcher):\n",
        "      student_optimizer.zero_grad()\n",
        "      comment = batch['comment_text'].to(device).squeeze(1)\n",
        "      logits = batch['logits'].to(device)\n",
        "      labels = batch['labels'].to(device)\n",
        "      n_ex += comment.size(0)\n",
        "\n",
        "      out = student_model(comment)\n",
        "      pred = (out.sigmoid() >= 0.5).long()\n",
        "      \n",
        "      # in case of minimizing for KLDivLoss:\n",
        "      \n",
        "      #out_bin = torch.stack([out, 1-out], -1)\n",
        "      #probs = logits.sigmoid()\n",
        "      #print(probs[torch.sum((probs>=0.5).long() != labels,-1).type(torch.BoolTensor)], labels[torch.sum((probs>=0.5).long() != labels,-1).type(torch.BoolTensor)])\n",
        "      #probs[torch.sum((probs>=0.5).long() != labels,-1).type(torch.BoolTensor)] = labels[torch.sum((probs>=0.5).long() != labels,-1).type(torch.BoolTensor)].float()\n",
        "      #probs_bin = torch.stack([probs, 1-probs], -1)\n",
        "      #loss = distill_criterion(out_bin.view(-1,2).log(), probs_bin.view(-1,2))\n",
        "      \n",
        "      loss = distill_criterion(out, logits)\n",
        "      \n",
        "      train_loss += loss.item()\n",
        "      loss.backward()\n",
        "      student_optimizer.step()\n",
        "      \n",
        "      train_exact_match += torch.sum(torch.sum(pred == labels, 1) == n_labels).item()\n",
        "      train_part_match += torch.sum(pred == labels).item()\n",
        "\n",
        "      if batch_id % print_every == 0 and batch_id > 0:\n",
        "        print(f'\\tIteration {batch_id}. Training loss: {(train_loss / batch_id):.7f}, full-match acc: {(train_exact_match / n_ex):.3f}, ' + \\\n",
        "        f'part-match acc {(train_part_match / n_ex / n_labels):.3f}')\n",
        "    \n",
        "    print(f'Epoch {epoch}. Training loss: {(train_loss / batch_id):.7f}, full-match acc: {(train_exact_match / n_ex):.3f}, ' + \\\n",
        "        f'part-match acc {(train_part_match / n_ex / n_labels):.3f}')\n",
        "    \n",
        "    with torch.no_grad():\n",
        "      teacher_model.eval()\n",
        "      val_loss = 0\n",
        "      n_ex = 0\n",
        "      val_exact_match = 0\n",
        "      val_part_match = 0\n",
        "      y_pred = []\n",
        "      y_true = []\n",
        "      student_dev_probs = []\n",
        "      \n",
        "      for batch_id, batch in enumerate(lr_dev_batcher):\n",
        "        comment = batch['comment_text'].to(device).squeeze(1)\n",
        "        logits = batch['logits'].to(device)\n",
        "        labels = batch['labels'].to(device)\n",
        "        n_ex += comment.size(0)\n",
        "        \n",
        "        out = student_model(comment.float())\n",
        "        student_dev_probs.append(out.sigmoid().detach().cpu().numpy())\n",
        "        pred = (out.sigmoid() >= 0.5).long()\n",
        "        \n",
        "        loss = distill_criterion(out, logits)\n",
        "        \n",
        "        val_loss += loss.item()\n",
        "        val_loss_list.append(loss.item())\n",
        "        \n",
        "        val_exact_match += torch.sum(torch.sum(pred == labels, 1) == n_labels).item()\n",
        "        val_part_match += torch.sum(pred == labels).item()\n",
        "        \n",
        "        y_pred += pred.tolist()\n",
        "        y_true += labels.tolist()\n",
        "\n",
        "        if batch_id % print_every == 0 and batch_id > 0:\n",
        "          print(f'\\tIteration {batch_id}. Validation loss: {(val_loss / batch_id):.7f}')\n",
        "      \n",
        "      val_loss /= batch_id\n",
        "      print(f'Epoch {epoch}. Validation loss: {val_loss:.7f}, full-match acc: {(val_exact_match / n_ex):.3f}, ' + \\\n",
        "        f'part-match acc {(val_part_match / n_ex / n_labels):.3f}')\n",
        "      \n",
        "      y_pred = np.array(y_pred)\n",
        "      y_true = np.array(y_true)\n",
        "      student_dev_probs = np.vstack(student_dev_probs)\n",
        "      roc_auc = report(y_true, student_dev_probs, label_names)\n",
        "      \n",
        "      if val_loss < lock_loss or epoch == 0:\n",
        "        lock_loss = val_loss\n",
        "        torch.save({'model_state_dict': student_model.state_dict(),\n",
        "                     'optimizer': student_optimizer.state_dict(),\n",
        "                     'loss': val_loss,\n",
        "                     'full-match acc': val_exact_match / n_ex,\n",
        "                     'part-match acc': val_part_match / n_ex / n_labels,\n",
        "                     'pred_true': (y_pred, y_true),\n",
        "                     'epoch': epoch}, 'drive/My Drive/toxic_distill/student.pt')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-NSdWx9NuSY",
        "colab_type": "text"
      },
      "source": [
        "### Report:\n",
        "\n",
        "CLASS: TOXIC\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.95      1.00      0.97     28877\n",
        "           1       0.96      0.52      0.68      3037\n",
        "\n",
        "\n",
        "ROC-AUC score: 0.9768482353862907\n",
        "\n",
        "CLASS: SEVERE_TOXIC\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.99      1.00      1.00     31603\n",
        "           1       0.52      0.30      0.38       311\n",
        "\n",
        "ROC-AUC score: 0.9894976188206317\n",
        "\n",
        "CLASS: OBSCENE\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.97      1.00      0.99     30245\n",
        "           1       0.92      0.52      0.66      1669\n",
        "\n",
        "ROC-AUC score: 0.9881755557098555\n",
        "\n",
        "CLASS: THREAT\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       1.00      1.00      1.00     31822\n",
        "           1       0.67      0.09      0.15        92\n",
        "\n",
        "ROC-AUC score: 0.9733107803461101\n",
        "\n",
        "CLASS: INSULT\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.97      1.00      0.98     30332\n",
        "           1       0.88      0.41      0.56      1582\n",
        "\n",
        "ROC-AUC score: 0.9825044892986223\n",
        "\n",
        "CLASS: IDENTITY_HATE\n",
        "\n",
        "              precision    recall  f1-score   support\n",
        "\n",
        "           0       0.99      1.00      1.00     31609\n",
        "           1       0.61      0.12      0.20       305\n",
        "\n",
        "ROC-AUC score: 0.9792807506058919\n",
        "\n",
        "**AVG ROC-AUC: 0.9816029050279004**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B8ohRQXkUZ3z",
        "colab_type": "code",
        "outputId": "2f306257-2993-4c87-fc52-461e0e7a949d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "student_model.load_state_dict(torch.load('drive/My Drive/toxic_distill/student.pt')['model_state_dict'])"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "IncompatibleKeys(missing_keys=[], unexpected_keys=[])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUz8t5sQT1iJ",
        "colab_type": "code",
        "outputId": "9fe22175-7041-4aae-e37a-9ca805d4def3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!pip install torchsummary"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torchsummary in /usr/local/lib/python3.6/dist-packages (1.5.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "21d7OVjAWVDk",
        "colab_type": "code",
        "outputId": "9d721a38-3d3c-4863-b978-0791bf978b95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        }
      },
      "source": [
        "from torchsummary import summary\n",
        "\n",
        "summary(student_model, (1, (n_word_features+n_char_features)))"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Linear-1                 [-1, 1, 6]         120,006\n",
            "================================================================\n",
            "Total params: 120,006\n",
            "Trainable params: 120,006\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.08\n",
            "Forward/backward pass size (MB): 0.00\n",
            "Params size (MB): 0.46\n",
            "Estimated Total Size (MB): 0.53\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8DOduYjijD4",
        "colab_type": "text"
      },
      "source": [
        "Вес student модели, кажется, достаточно мал $\\sim 0.53 ~Mb$. Плюс спарс-матрица tf-idf. \n",
        "\n",
        "В скорости инференса у такой модели тоже не занимать - одно умножение матрицы на вектор + сигмоида.\n",
        "\n",
        "Куда уж меньше?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBmMX4BAhTja",
        "colab_type": "text"
      },
      "source": [
        "## Pure student:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ljRkTAHZo5_",
        "colab_type": "text"
      },
      "source": [
        "Теперь проверим, сколько даёт логистическаая регрессия без дистилляции:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhhuKzu5OEyf",
        "colab_type": "code",
        "outputId": "59eee4e8-c4b5-4054-d294-695a2e3045d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        }
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "train_word_features = word_vectorizer.transform(train_df['comment_text'])\n",
        "train_char_features = char_vectorizer.transform(train_df['comment_text'])\n",
        "dev_word_features = word_vectorizer.transform(dev_df['comment_text'])\n",
        "dev_char_features = char_vectorizer.transform(dev_df['comment_text'])\n",
        "\n",
        "train_features = hstack([train_char_features, train_word_features])\n",
        "dev_features = hstack([dev_char_features, dev_word_features])\n",
        "\n",
        "scores = []\n",
        "for i, name in enumerate(label_names):\n",
        "    lr_clf = LogisticRegression(C=0.1, solver='sag')\n",
        "    lr_clf.fit(train_features, train_df[name])\n",
        "    probs = lr_clf.predict_proba(dev_features)\n",
        "    scores.append(roc_auc_score(dev_df[name], probs[:,1]))\n",
        "    print(f'roc-auc for class {name}: {scores[-1]}')\n",
        "print(f'avg roc-auc: {np.mean(scores)}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "roc-auc for class toxic: 0.9680880663229708\n",
            "roc-auc for class severe_toxic: 0.9889524713403312\n",
            "roc-auc for class obscene: 0.9833513623165955\n",
            "roc-auc for class threat: 0.9782806808524592\n",
            "roc-auc for class insult: 0.9746717031059396\n",
            "roc-auc for class identity_hate: 0.9777377163279395\n",
            "avg roc-auc: 0.9785136667110393\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DoIFcp7DpvXp",
        "colab_type": "text"
      },
      "source": [
        "В итоге мой подход сократил количество ошибок на $14\\%$. Сократил бы на $46$ - выиграл бы challenge."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLd67DITTh3L",
        "colab_type": "text"
      },
      "source": [
        "## Интерпретируемость:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqlASD2ie_dn",
        "colab_type": "text"
      },
      "source": [
        "В качестве интерпретации модели, я вывел 10 самых значимых признаков для каждого класса. Значимость оценивается как величина абсолютного значения нейрона между признаком и классом. \n",
        "\n",
        "Получилось забавно, но немного однообразно. Уж простите за обсценную лексику, но больше её избегать не получится."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fqdODYgTun_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weights = student_model.lin.weight.data\n",
        "abs_weights = weights.abs()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYAWqp_qZxjy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k = 10\n",
        "topk = torch.topk(abs_weights, k, dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vXA00d4TTg_j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word_features = word_vectorizer.get_feature_names()\n",
        "char_features = char_vectorizer.get_feature_names()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szNCcS5Xarbg",
        "colab_type": "code",
        "outputId": "fd72ad18-26e2-4272-a14e-e43da7dfe783",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "for i, name in enumerate(label_names):\n",
        "  class_features = [((word_features+char_features)[idx.item()]) for idx, val in zip(topk.indices[i], topk.values[i])]\n",
        "  print(name)\n",
        "  print(class_features)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "toxic\n",
            "['idiot', 'stupid', 'crap', 'moron', 'uck', 'penis', 'ass', 'asshole', 'gay', 'hell']\n",
            "severe_toxic\n",
            "['stupid', 'ass', 'idiot', 'asshole', 'uck', 'penis', 'fuc', 'cunt', 'fuck', 'gay']\n",
            "obscene\n",
            "['stupid', 'idiot', 'ass', 'crap', 'uck', 'penis', 'bullshit', 'asshole', 'cunt', 'damn']\n",
            "threat\n",
            "['die', 'kill', 'gay', 'stupid', 'nazi', 'hell', 'crap', 'penis', 'hate', 'ass']\n",
            "insult\n",
            "['idiot', 'stupid', 'moron', 'crap', 'gay', 'asshole', 'ass', 'uck', 'idiots', 'cunt']\n",
            "identity_hate\n",
            "['gay', 'stupid', 'nazi', 'nigger', 'idiot', 'fag', 'faggot', 'jew', 'nigg', 'racist']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GRd0T0qsfifv",
        "colab_type": "text"
      },
      "source": [
        "## Как можно улучшить модель?\n",
        "\n",
        "1. Лучше обучить учителя.\n",
        "2. Взять BERT Large  в качестве учителя)\n",
        "3. Сделать ансамбль студентов, можно даже с разными архитектурами.\n",
        "4. Увеличить количество признаков. Можно собрать другие полезные статистики, кроме tf-idf на униграммах и символах. Например, на биграммах и триграммах), чтобы учитывать наличие специфических словосочетаний.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVu8gcxIc5L6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}